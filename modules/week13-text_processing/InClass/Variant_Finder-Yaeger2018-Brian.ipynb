{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in dataframe\n",
    "df = pd.read_excel(\"Yaeger2018.xlsx\", header=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select certain columns\n",
    "df =  df[df.columns[0:4]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select certain columns\n",
    "columns = ['Hugo_Symbol', 'HGVSc', 'HGVSp_Short', 'dbSNP_RS']\n",
    "\n",
    "#fill any empty cell with an na value\n",
    "df[columns] = df[columns].fillna(\"\")\n",
    "print(len(df))\n",
    "\n",
    "#Drop any duplicate values\n",
    "df.drop_duplicates(['HGVSc'], inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ('AKT1',\n",
    "'APC',\n",
    "'APLF',\n",
    "'ARID1A',\n",
    "'AR',\n",
    "'ATM',\n",
    "'ATR',\n",
    "'FRP1',\n",
    "'AXIN2',\n",
    "'BARD1',\n",
    "'BLM',\n",
    "'BMPR1A',\n",
    "'BRAF',\n",
    "'BRCA1',\n",
    "'BRCA2',\n",
    "'BRIP1',\n",
    "'BTG2',\n",
    "'CCND3',\n",
    "'CCNE1',\n",
    "'CDH1',\n",
    "'CDK4',\n",
    "'CDK12',\n",
    "'CDKN1B',\n",
    "'CHD4',\n",
    "'CHEK1',\n",
    "'CHEK2',\n",
    "'KIT',\n",
    "'CSMD3',\n",
    "'CTCF',\n",
    "'CUL3',\n",
    "'DDR2',\n",
    "'DHX9',\n",
    "'BAP1',\n",
    "'DNMT3A',\n",
    "'EGFR',\n",
    "'ERBB1',\n",
    "'EDNRB',\n",
    "'ELF3',\n",
    "'EMSY',\n",
    "'EP300',\n",
    "'EPCAM',\n",
    "'ERBB2',\n",
    "'ERBB2IP',\n",
    "'ERCC1',\n",
    "'ERCC2',\n",
    "'ERCC3',\n",
    "'ERCC5',\n",
    "'EYA4',\n",
    "'FGFR2',\n",
    "'FGFR3',\n",
    "'FGFR4',\n",
    "'FAM123B ',\n",
    "'AMER1',\n",
    "'FAM175A',\n",
    "'ABRAXAS1',\n",
    "'FANCA',\n",
    "'FANCD2',\n",
    "'FANCI',\n",
    "'FANCL',\n",
    "'FANCM',\n",
    "'SLX4 ',\n",
    "'ABRAXAS1',\n",
    "'FBXW7',\n",
    "'FOXA1',\n",
    "'FOXP1',\n",
    "'FOXQ1',\n",
    "'GATA3',\n",
    "'GREM1',\n",
    "'GALNT12',\n",
    "'FGFR1',\n",
    "'HOXB13',\n",
    "'PSGD',\n",
    "'HDAC2',\n",
    "'KDM6A',\n",
    "'KEAP1',\n",
    "'KRAS',\n",
    "'KLF5',\n",
    "'KMT2D',\n",
    "'KMT2C',\n",
    "'KMT2B',\n",
    "'MAP2K1',\n",
    "'MAP2K2',\n",
    "'MAP2K4',\n",
    "'MAP3K1',\n",
    "'MET',\n",
    "'MLH1',\n",
    "'MLH3',\n",
    "'MLLT4',\n",
    "'MRE11A',\n",
    "'MSH2',\n",
    "'MSH3',\n",
    "'MSH6',\n",
    "'NBN',\n",
    "'NCOR1',\n",
    "'NCOR2',\n",
    "'NF1',\n",
    "'NFE2L2',\n",
    "'NTHL1',\n",
    "'NOTCH1',\n",
    "'NOTCH2',\n",
    "'NRAS',\n",
    "'PAIP1',\n",
    "'MYH',\n",
    "'PALB2',\n",
    "'PIK3CA',\n",
    "'PMS2',\n",
    "'POLD1',\n",
    "'POLE',\n",
    "'POLG',\n",
    "'POLH',\n",
    "'POLN',\n",
    "'POLQ',\n",
    "'PPPRR2A',\n",
    "'PRKDC',\n",
    "'PSMC3IP',\n",
    "'PTPRD',\n",
    "'PTEN',\n",
    "'CDKN2A',\n",
    "'P14ARF',\n",
    "'P16',\n",
    "'RAD51',\n",
    "'RAD51B',\n",
    "'RAD51C',\n",
    "'RAD51D',\n",
    "'RAD54L',\n",
    "'RB1',\n",
    "'RECQL',\n",
    "'RBM10',\n",
    "'RET',\n",
    "'REV3L',\n",
    "'RFC4',\n",
    "'RHOA',\n",
    "'RHOB',\n",
    "'RIF1',\n",
    "'RINT1',\n",
    "'RPS20',\n",
    "'PPP2R2A',\n",
    "'RAD50',\n",
    "'REPA1',\n",
    "'RNF43',\n",
    "'RUNX1',\n",
    "'RXRA',\n",
    "'SCG5',\n",
    "'SF3B1',\n",
    "'SMAD2',\n",
    "'SMAD4',\n",
    "'SMARCA1',\n",
    "'SMARCA4',\n",
    "'SOX9',\n",
    "'SPOP',\n",
    "'STAG2',\n",
    "'STK11',\n",
    "'TCF7L2',\n",
    "'TP53',\n",
    "'TSC1',\n",
    "'TXNIP',\n",
    "'TOP1',\n",
    "'TOPO1',\n",
    "'U2AF1',\n",
    "'ZFP36L1',\n",
    "'ZFP36L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[df['Hugo_Symbol'].isin(genes)]\n",
    "print(len(df2))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Variants\n",
    "### c. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_txt_c = \" \".join([x for x in df2.iloc[:, 1]])\n",
    "tst_txt_c[:1888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_txt_c = \" \".join([x for x in df2.iloc[:, 1]])\n",
    "V_name = re.compile(r\"\"\"c\\.(?P<nucltide_pos>\\d+)(?P<wild_type_Base>[ACTG])>(?P<variant_Base>[ACTG])\"\"\")\n",
    "\n",
    "\n",
    "Variant = []\n",
    "nucltide_pos = []\n",
    "wild_type_Base = []\n",
    "variant_Base = []\n",
    "\n",
    "# for n in V_name.finditer(tst_txt_c):\n",
    "#     Variant.append(n.group())\n",
    "# print(len(Variant))\n",
    "# Variant\n",
    "\n",
    "# # for n in V_name.finditer(tst_txt_c):\n",
    "# #     nucltide_pos.append(n.group('nucltide_pos'))\n",
    "# # print(len(nucltide_pos))\n",
    "# # nucltide_pos\n",
    "\n",
    "# # for n in V_name.finditer(tst_txt_c):\n",
    "# #     wild_type_Base.append(n.group('wild_type_Base'))\n",
    "# # print(len(wild_type_Base))\n",
    "# # wild_type_Base\n",
    "\n",
    "# # for n in V_name.finditer(tst_txt_c):\n",
    "# #     variant_Base.append(n.group('variant_Base'))\n",
    "# # print(len(variant_Base))\n",
    "# # variant_Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_txt_c2 = \" \".join([x for x in df2.iloc[:, 2]])\n",
    "tst_txt_c2[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_txt_c2 = \" \".join([x for x in df2.iloc[:, 2]])\n",
    "V_name1 = re.compile(r\"\"\"c\\..\\S+\"\"\")\n",
    "V_name2 = re.compile(r\"\"\"c\\.(?P<nucltide_pos>\\d*)\"\"\")\n",
    "V_name3 = re.compile(r\"\"\"p\\.[a-zA-z]+(?P<codon>\\d+)\"\"\")\n",
    "\n",
    "Variant_all = []\n",
    "codon = []\n",
    "c_dot = []\n",
    "\n",
    "for n in V_name1.finditer(tst_txt_c):\n",
    "    Variant_all.append(n.group())\n",
    "print(len(Variant_all))\n",
    "Variant_all\n",
    "\n",
    "for n in V_name2.finditer(tst_txt_c):\n",
    "    c_dot.append(n.group('nucltide_pos'))\n",
    "print(len(c_dot))\n",
    "c_dot\n",
    "\n",
    "for n in V_name3.finditer(tst_txt_c2):\n",
    "    codon.append(n.group('codon'))\n",
    "print(len(codon))\n",
    "codon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# V_name2 = re.compile(r\"\"\"(?<=:|/^)c\\..+\"\"\")\n",
    "# Cdna_snv = []\n",
    "# for index, row in df2.iterrows():\n",
    "#     for n in V_name2.finditer(row.HGVSc):\n",
    "#         Cdna_snv.append(n.group())    \n",
    "#     #print(row.HGVSc)\n",
    "# print(len(Cdna_snv))\n",
    "# Cdna_snv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace old Column's values with new ones  \n",
    "df2['HGVSc'] = Cdna_snv\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('Yaeger2018_variants.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df2.to_excel(writer, sheet_name='Yaeger2018')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Compare the resulting dataframe with the original, returns the rows that are not in the second dataset\n",
    "# df3 = df3.reset_index(drop=True)\n",
    "# df_gpby = df3.groupby(list(df3.columns))\n",
    "# idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "# df3.reindex(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next three cells will generate three separate dataframes with all the separated components of a name. These dataframes correspond to the 3 different variant types that we deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snv_Table = pd.DataFrame(list(zip(n[\"snv_vnt_fullname\"], Gene_snv, WTAAsnv, s[\"codon_snv\"], vnt_AA_3code, s[\"WTBsnv\"], s[\"Cdna_snv\"], s[\"vnt_Bsnv\"])),\n",
    "                         columns=['Variant_Name', 'Gene_Name', 'Wildtype_Amino_Acid', 'Codon',\n",
    "                                  'Variant_Amino_Acid', 'Wildtype_Seq', 'Cdna_Position_Number', 'Variant_Seq'])\n",
    "snv_Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_Table = pd.DataFrame(list(zip(n[\"vnt_fullnameFS\"], Gene_FS, WTAA_FS, s[\"codonFS\"], vnt_AA_3codeFS, WTBFS, s[\"CdnaFS\"], vnt_BFS)),\n",
    "                        columns=['Variant_Name', 'Gene_Name', 'Wildtype_Amino_Acid', 'Codon',\n",
    "                                 'Variant_Amino_Acid', 'Wildtype_Seq', 'Cdna_Position_Number', 'Variant_Seq'])\n",
    "FS_Table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Splice_Table = pd.DataFrame(list(zip(s[\"c_splice3\"], Gene_spl, s[\"WTBspl\"], s[\"Cdnaspl\"], s[\"vnt_Bspl\"])),\n",
    "                            columns=['Variant_Name', 'Gene_Name', 'Wildtype_Seq', 'Cdna_Position_Number',\n",
    "                                     'Variant_Seq'])\n",
    "Splice_Table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will join the last three tables to generate the final dataframe with all the variant types, their full name and separated name components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_Tables = snv_Table.append([FS_Table, Splice_Table])\n",
    "Individual_values_Table = joining_Tables.reindex_axis(\n",
    "    snv_Table.columns, axis=1).fillna(\"\")\n",
    "Individual_values_Table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are ready to write these into a database:\n",
    "   #### Connect to a sqlite3 database and create a table with our generated dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn = sqlite3.connect(\":MEMORY:\")\n",
    "curs = db_conn.cursor()\n",
    "Individual_values_Table.to_sql(\n",
    "    \"Variant_Ref1\", db_conn, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM Variant_Ref1\"\n",
    "df = pd.read_sql_query(sql, db_conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute('SELECT Variant_Name FROM Variant_Ref1 WHERE Codon=\"340\"')\n",
    "curs.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### close the connection to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create 3 new instances of our class Variant: instances are variants that we want on \"spot light\" to do more work with them at a later time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variant(vname=\"c.1090A>T (p.Thr364Ser)\", gene=\"CDH1\")\n",
    "print(a)\n",
    "c = Variant(vname=\"c.1003C>T (p.Arg335*)\", gene=\"CDH1\")\n",
    "print(c)\n",
    "d = Variant(vname=\"c.1018A>G (p.Thr340Ala)\", gene=\"CDH1\")\n",
    "print(d)\n",
    "d.how_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.del_variant()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of the VntCount class, which inherits from the Variant class. \n",
    "#### It tells you how many variants are in your final dataframe, and the number of variants on \"spot light\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = VntCount(vname=\"c.1090A>T (p.Thr364Ser)\", gene=\"CDH1\",\n",
    "             dataF=Individual_values_Table, dfname=\"Individual_values_Table\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a bar graph from your final dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing(Individual_values_Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
